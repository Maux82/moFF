{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Local Regression (LOESS) estimation routine.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def loc_eval(x, b):\n",
    "    \"\"\"\n",
    "    Evaluate `x` using locally-weighted regression parameters.\n",
    "    Degree of polynomial used in loess is inferred from b. `x`\n",
    "    is assumed to be a scalar.\n",
    "    \"\"\"\n",
    "    loc_est = 0\n",
    "    for i in enumerate(b): loc_est+=i[1]*(x**i[0])\n",
    "    return(loc_est)\n",
    "\n",
    "\n",
    "\n",
    "def loess(xvals, yvals, alpha, poly_degree=1):\n",
    "    \"\"\"\n",
    "    Perform locally-weighted regression on xvals & yvals.\n",
    "    Variables used inside `loess` function:\n",
    "\n",
    "        n         => number of data points in xvals\n",
    "        m         => nbr of LOESS evaluation points\n",
    "        q         => number of data points used for each\n",
    "                     locally-weighted regression\n",
    "        v         => x-value locations for evaluating LOESS\n",
    "        locsDF    => contains local regression details for each\n",
    "                     location v\n",
    "        evalDF    => contains actual LOESS output for each v\n",
    "        X         => n-by-(poly_degree+1) design matrix\n",
    "        W         => n-by-n diagonal weight matrix for each\n",
    "                     local regression\n",
    "        y         => yvals\n",
    "        b         => local regression coefficient estimates.\n",
    "                     b = `(X^T*W*X)^-1*X^T*W*y`. Note that `@`\n",
    "                     replaces `np.dot` in recent numpy versions.\n",
    "        local_est => response for local regression\n",
    "    \"\"\"\n",
    "    # Sort dataset by xvals.\n",
    "    all_data = sorted(zip(xvals, yvals), key=lambda x: x[0])\n",
    "    xvals, yvals = zip(*all_data)\n",
    "\n",
    "    locsDF = pd.DataFrame(\n",
    "                columns=[\n",
    "                  'loc','x','weights','v','y','raw_dists',\n",
    "                  'scale_factor','scaled_dists'\n",
    "                  ])\n",
    "    evalDF = pd.DataFrame(\n",
    "                columns=[\n",
    "                  'loc','est','b','v','g'\n",
    "                  ])\n",
    "\n",
    "    n = len(xvals)\n",
    "    m = n + 1\n",
    "    q = int(np.floor(n * alpha) if alpha <= 1.0 else n)\n",
    "    avg_interval = ((max(xvals)-min(xvals))/len(xvals))\n",
    "    v_lb = max(0,min(xvals)-(.5*avg_interval))\n",
    "    v_ub = (max(xvals)+(.5*avg_interval))\n",
    "    v = enumerate(np.linspace(start=v_lb, stop=v_ub, num=m), start=1)\n",
    "\n",
    "    # Generate design matrix based on poly_degree.\n",
    "    xcols = [np.ones_like(xvals)]\n",
    "    for j in range(1, (poly_degree + 1)):\n",
    "        xcols.append([i ** j for i in xvals])\n",
    "    X = np.vstack(xcols).T\n",
    "\n",
    "\n",
    "    for i in v:\n",
    "\n",
    "        iterpos = i[0]\n",
    "        iterval = i[1]\n",
    "\n",
    "        # Determine q-nearest xvals to iterval.\n",
    "        iterdists = sorted([(j, np.abs(j-iterval)) \\\n",
    "                           for j in xvals], key=lambda x: x[1])\n",
    "\n",
    "        _, raw_dists = zip(*iterdists)\n",
    "\n",
    "        # Scale local observations by qth-nearest raw_dist.\n",
    "        scale_fact = raw_dists[q-1]\n",
    "        scaled_dists = [(j[0],(j[1]/scale_fact)) for j in iterdists]\n",
    "        weights = [(j[0],((1-np.abs(j[1]**3))**3 \\\n",
    "                      if j[1]<=1 else 0)) for j in scaled_dists]\n",
    "\n",
    "        # Remove xvals from each tuple:\n",
    "        _, weights      = zip(*sorted(weights,     key=lambda x: x[0]))\n",
    "        _, raw_dists    = zip(*sorted(iterdists,   key=lambda x: x[0]))\n",
    "        _, scaled_dists = zip(*sorted(scaled_dists,key=lambda x: x[0]))\n",
    "\n",
    "        iterDF1 = pd.DataFrame({\n",
    "                    'loc'         :iterpos,\n",
    "                    'x'           :xvals,\n",
    "                    'v'           :iterval,\n",
    "                    'weights'     :weights,\n",
    "                    'y'           :yvals,\n",
    "                    'raw_dists'   :raw_dists,\n",
    "                    'scale_fact'  :scale_fact,\n",
    "                    'scaled_dists':scaled_dists\n",
    "                    })\n",
    "\n",
    "        locsDF    = pd.concat([locsDF, iterDF1])\n",
    "        W         = np.diag(weights)\n",
    "        y         = yvals\n",
    "        b         = np.linalg.inv(X.T @ W @ X) @ (X.T @ W @ y)\n",
    "        local_est = loc_eval(iterval, b)\n",
    "        iterDF2   = pd.DataFrame({\n",
    "                       'loc':[iterpos],\n",
    "                       'b'  :[b],\n",
    "                       'v'  :[iterval],\n",
    "                       'g'  :[local_est]\n",
    "                       })\n",
    "\n",
    "        evalDF = pd.concat([evalDF, iterDF2])\n",
    "\n",
    "    # Reset indicies for returned DataFrames.\n",
    "    locsDF.reset_index(inplace=True)\n",
    "    locsDF.drop('index', axis=1, inplace=True)\n",
    "    locsDF['est'] = 0; evalDF['est'] = 0\n",
    "    locsDF = locsDF[['loc','est','v','x','y','raw_dists',\n",
    "                     'scale_fact','scaled_dists','weights']]\n",
    "\n",
    "    # Reset index for evalDF.\n",
    "    evalDF.reset_index(inplace=True)\n",
    "    evalDF.drop('index', axis=1, inplace=True)\n",
    "    evalDF = evalDF[['loc','est', 'v', 'b', 'g']]\n",
    "\n",
    "    return(locsDF, evalDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a.argentini\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:107: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\nC:\\Users\\a.argentini\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:119: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(16)\n",
    "\n",
    "xvals = [.39,.75,1.1,1.45,1.95,2.46,3.07,3.44,4.57,5.05,5.68,\n",
    "         6.01,6.63,7.11,7.62,8.01,8.54,9.08,9.48, 9.91]\n",
    "\n",
    "yvals = [1.25*np.sqrt(i)+np.random.normal(0, .425) for i in xvals]\n",
    "\n",
    "# loess returns a tuple of DataFrames, named here as `regsDF` and\n",
    "# `evalDF` for \"Regression DataFrame\" and \"Evaluation DataFrame\":\n",
    "regsDF, evalDF = loess(xvals, yvals, alpha=.6, poly_degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loc  est        v     x         y  raw_dists  scale_fact  scaled_dists  \\\n0     1    0   0.1520  0.39  0.835003     0.2380      5.8580      0.040628   \n1     1    0   0.1520  0.75  0.432931     0.5980      5.8580      0.102083   \n2     1    0   0.1520  1.10  1.058362     0.9480      5.8580      0.161830   \n3     1    0   0.1520  1.45  1.533390     1.2980      5.8580      0.221577   \n4     1    0   0.1520  1.95  1.220445     1.7980      5.8580      0.306931   \n5     1    0   0.1520  2.46  1.696467     2.3080      5.8580      0.393991   \n6     1    0   0.1520  3.07  1.812374     2.9180      5.8580      0.498122   \n7     1    0   0.1520  3.44  2.530441     3.2880      5.8580      0.561284   \n8     1    0   0.1520  4.57  2.337764     4.4180      5.8580      0.754182   \n9     1    0   0.1520  5.05  2.859492     4.8980      5.8580      0.836122   \n10    1    0   0.1520  5.68  2.657427     5.5280      5.8580      0.943667   \n11    1    0   0.1520  6.01  3.274094     5.8580      5.8580      1.000000   \n12    1    0   0.1520  6.63  2.861851     6.4780      5.8580      1.105838   \n13    1    0   0.1520  7.11  2.901689     6.9580      5.8580      1.187777   \n14    1    0   0.1520  7.62  3.304973     7.4680      5.8580      1.274838   \n15    1    0   0.1520  8.01  4.338640     7.8580      5.8580      1.341413   \n16    1    0   0.1520  8.54  3.537772     8.3880      5.8580      1.431888   \n17    1    0   0.1520  9.08  3.149649     8.9280      5.8580      1.524070   \n18    1    0   0.1520  9.48  3.389634     9.3280      5.8580      1.592352   \n19    1    0   0.1520  9.91  5.025177     9.7580      5.8580      1.665756   \n20    2    0   0.6518  0.39  0.835003     0.2618      5.3582      0.048860   \n21    2    0   0.6518  0.75  0.432931     0.0982      5.3582      0.018327   \n22    2    0   0.6518  1.10  1.058362     0.4482      5.3582      0.083647   \n23    2    0   0.6518  1.45  1.533390     0.7982      5.3582      0.148968   \n24    2    0   0.6518  1.95  1.220445     1.2982      5.3582      0.242283   \n25    2    0   0.6518  2.46  1.696467     1.8082      5.3582      0.337464   \n26    2    0   0.6518  3.07  1.812374     2.4182      5.3582      0.451308   \n27    2    0   0.6518  3.44  2.530441     2.7882      5.3582      0.520361   \n28    2    0   0.6518  4.57  2.337764     3.9182      5.3582      0.731253   \n29    2    0   0.6518  5.05  2.859492     4.3982      5.3582      0.820835   \n..   ..  ...      ...   ...       ...        ...         ...           ...   \n390  20    0   9.6482  5.68  2.657427     3.9682      5.0782      0.781419   \n391  20    0   9.6482  6.01  3.274094     3.6382      5.0782      0.716435   \n392  20    0   9.6482  6.63  2.861851     3.0182      5.0782      0.594344   \n393  20    0   9.6482  7.11  2.901689     2.5382      5.0782      0.499823   \n394  20    0   9.6482  7.62  3.304973     2.0282      5.0782      0.399393   \n395  20    0   9.6482  8.01  4.338640     1.6382      5.0782      0.322595   \n396  20    0   9.6482  8.54  3.537772     1.1082      5.0782      0.218227   \n397  20    0   9.6482  9.08  3.149649     0.5682      5.0782      0.111890   \n398  20    0   9.6482  9.48  3.389634     0.1682      5.0782      0.033122   \n399  20    0   9.6482  9.91  5.025177     0.2618      5.0782      0.051554   \n400  21    0  10.1480  0.39  0.835003     9.7580      5.5780      1.749373   \n401  21    0  10.1480  0.75  0.432931     9.3980      5.5780      1.684833   \n402  21    0  10.1480  1.10  1.058362     9.0480      5.5780      1.622087   \n403  21    0  10.1480  1.45  1.533390     8.6980      5.5780      1.559340   \n404  21    0  10.1480  1.95  1.220445     8.1980      5.5780      1.469702   \n405  21    0  10.1480  2.46  1.696467     7.6880      5.5780      1.378272   \n406  21    0  10.1480  3.07  1.812374     7.0780      5.5780      1.268914   \n407  21    0  10.1480  3.44  2.530441     6.7080      5.5780      1.202582   \n408  21    0  10.1480  4.57  2.337764     5.5780      5.5780      1.000000   \n409  21    0  10.1480  5.05  2.859492     5.0980      5.5780      0.913948   \n410  21    0  10.1480  5.68  2.657427     4.4680      5.5780      0.801004   \n411  21    0  10.1480  6.01  3.274094     4.1380      5.5780      0.741843   \n412  21    0  10.1480  6.63  2.861851     3.5180      5.5780      0.630692   \n413  21    0  10.1480  7.11  2.901689     3.0380      5.5780      0.544640   \n414  21    0  10.1480  7.62  3.304973     2.5280      5.5780      0.453209   \n415  21    0  10.1480  8.01  4.338640     2.1380      5.5780      0.383292   \n416  21    0  10.1480  8.54  3.537772     1.6080      5.5780      0.288275   \n417  21    0  10.1480  9.08  3.149649     1.0680      5.5780      0.191466   \n418  21    0  10.1480  9.48  3.389634     0.6680      5.5780      0.119756   \n419  21    0  10.1480  9.91  5.025177     0.2380      5.5780      0.042668   \n\n      weights  \n0    0.999799  \n1    0.996812  \n2    0.987339  \n3    0.967718  \n4    0.915739  \n5    0.827516  \n6    0.673150  \n7    0.557794  \n8    0.186197  \n9    0.071715  \n10   0.004070  \n11   0.000000  \n12   0.000000  \n13   0.000000  \n14   0.000000  \n15   0.000000  \n16   0.000000  \n17   0.000000  \n18   0.000000  \n19   0.000000  \n20   0.999650  \n21   0.999982  \n22   0.998245  \n23   0.990115  \n24   0.957937  \n25   0.889081  \n26   0.748806  \n27   0.634058  \n28   0.225840  \n29   0.089282  \n..        ...  \n390  0.142936  \n391  0.252758  \n392  0.493134  \n393  0.670227  \n394  0.820790  \n395  0.902629  \n396  0.969145  \n397  0.995804  \n398  0.999891  \n399  0.999589  \n400  0.000000  \n401  0.000000  \n402  0.000000  \n403  0.000000  \n404  0.000000  \n405  0.000000  \n406  0.000000  \n407  0.000000  \n408  0.000000  \n409  0.013241  \n410  0.114841  \n411  0.207202  \n412  0.420405  \n413  0.589413  \n414  0.745924  \n415  0.840403  \n416  0.929839  \n417  0.979090  \n418  0.994856  \n419  0.999767  \n\n[420 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print (regsDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
